{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRAIN G600:\n",
    "Modelos de clasificación de trigo y maiz, se entrena un modelo para clasificar todo el grano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, Activation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
    "\n",
    "import  imblearn\n",
    "from imblearn.over_sampling import  ADASYN\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "#from PIL import image\n",
    "#import tensorflow-gpu\n",
    "#from bayes_opt import BayesianOptimization\n",
    "\n",
    "\n",
    "print(tf.__version__)\n",
    "#tf.debugging.set_log_device_placement(True)\n",
    "#-------------------------------------------------------------------------------\n",
    "import time\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iniciamos configurando tensorflow para usar la GPU, al igual que tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "if len(tf.config.list_physical_devices('GPU'))>0:\n",
    "    physical_devices = tf.config.list_physical_devices('GPU')\n",
    "    print(physical_devices)\n",
    "    tf.config.experimental.set_virtual_device_configuration(physical_devices[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)])\n",
    "    print(\"Virtual GPU devices: \", tf.config.list_logical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.debugging.set_log_device_placement(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metricas a seguir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([16, 32]))\n",
    "HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.1, 0.2))\n",
    "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd']))\n",
    "\n",
    "METRIC_ACCURACY = 'accuracy'\n",
    "METRIC_LOSS = 'loss'\n",
    "\n",
    "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "  hp.hparams_config(\n",
    "    hparams=[HP_NUM_UNITS, HP_DROPOUT, HP_OPTIMIZER],\n",
    "    metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy'), hp.Metric(METRIC_LOSS, display_name='Loss')],\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ambos granos: Trigo y Maiz\n",
    "Generamos dos iteradores de carpetas para los conjuntos de datos de validación y de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directorios de entrenamiento y validación r\"../../grainspace/M600/pre/both/\n",
    "train_dir = '../grainspace/M600/pre/both/train'\n",
    "validation_dir = '../grainspace/M600/pre/both/validation'\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,          # Normaliza los valores de los píxeles\n",
    "    shear_range=0.2,         # Aplica transformaciones de corte\n",
    "    zoom_range=0.2,          # Aplica zoom aleatorio\n",
    "    horizontal_flip=True     # Invierte las imágenes horizontalmente\n",
    ")\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    train_dir,  # Directorio con las imágenes de entrenamiento\n",
    "    target_size=(150, 150),     # Tamaño de las imágenes\n",
    "    batch_size=32,              # Tamaño del lote\n",
    "    class_mode='categorical'         # Tipo de clasificación (binary, categorical, etc.)\n",
    ")\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_images, batch_labels = next(train_generator)\n",
    "\n",
    "# Assuming the images are in the first channel of the batch\n",
    "sample_images = batch_images[:, :, :, 0]\n",
    "\n",
    "# Plot the first few images\n",
    "num_images_to_plot = 5\n",
    "fig, axes = plt.subplots(1, num_images_to_plot, figsize=(15, 5))\n",
    "for i in range(num_images_to_plot):\n",
    "    axes[i].imshow(sample_images[i])\n",
    "    axes[i].axis('on')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la arquitectura del modelo, de forma iterativa, para obetner los mejores hiperparametros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(hparams,logdir):\n",
    "\n",
    "  model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(hparams[HP_NUM_UNITS], (3, 3), activation='relu'),\n",
    "\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(hparams[HP_NUM_UNITS], activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\n",
    "    tf.keras.layers.Dense(len(train_generator.class_indices), activation=tf.nn.softmax),\n",
    "  ])\n",
    "  tensorboard = TensorBoard(log_dir=\"logs/G600_both/HPtuning/{}\".format(time.time()))\n",
    "  early_stopping = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "\n",
    "  model.compile(\n",
    "      optimizer=hparams[HP_OPTIMIZER],\n",
    "      loss='binary_crossentropy',\n",
    "      metrics=['accuracy'],\n",
    "  )\n",
    "\n",
    "  model.fit(train_generator,\n",
    "            steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "            validation_data=validation_generator,\n",
    "            validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
    "            epochs=1,\n",
    "            callbacks=[tensorboard,early_stopping, # log metrics\n",
    "                      hp.KerasCallback(logdir, hparams)])  # log hparams\n",
    "                       # Run with 1 epoch to speed things up for demo purposes\n",
    "  loss, accuracy = model.evaluate(validation_generator)\n",
    "  model.summary()\n",
    "  print('Loss: {0:.4f}, Accuracy: {1:.4f}'.format(loss, accuracy))\n",
    "  return loss, accuracy\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(run_dir, hparams):\n",
    "  with tf.summary.create_file_writer(run_dir).as_default():\n",
    "    hp.hparams(hparams)  # record the values used in this trial\n",
    "    loss, accuracy = train_test_model(hparams,run_dir)\n",
    "    tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
    "    epochs=90,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.TensorBoard(logdir),  # log metrics\n",
    "        hp.KerasCallback(logdir, hparams),  # log hparams\n",
    "    ]\n",
    ")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_num = 0\n",
    "\n",
    "for num_units in HP_NUM_UNITS.domain.values:\n",
    "  for dropout_rate in (HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value):\n",
    "    for optimizer in HP_OPTIMIZER.domain.values:\n",
    "      hparams = {\n",
    "          HP_NUM_UNITS: num_units,\n",
    "          HP_DROPOUT: dropout_rate,\n",
    "          HP_OPTIMIZER: optimizer,\n",
    "      }\n",
    "      run_name = \"run-%d\" % session_num\n",
    "      print('--- Starting trial: %s' % run_name)\n",
    "      print({h.name: hparams[h] for h in hparams})\n",
    "      run('logs/hparam_tuning/' + run_name, hparams)\n",
    "      session_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ok': True, 'result': {'message_id': 4, 'from': {'id': 7448990665, 'is_bot': True, 'first_name': 'VS Code Done!', 'username': 'VSC_noti_bot'}, 'chat': {'id': 1298690395, 'first_name': 'Omarciano', 'type': 'private'}, 'date': 1723268183, 'text': '¡La compilación en VS Code ha terminado!'}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def send_telegram_message(token, chat_id, message):\n",
    "    url = f\"https://api.telegram.org/bot{token}/sendMessage\"\n",
    "    payload = {\n",
    "        \"chat_id\": chat_id,\n",
    "        \"text\": message\n",
    "    }\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    response = requests.post(url, json=payload, headers=headers)\n",
    "    return response\n",
    "\n",
    "# Reemplaza con tu token y chat_id\n",
    "telegram_token = \"7448990665:AAEBnXWdATGjB6UOQRdYW6uztDbzjDk8OA4\"\n",
    "chat_id = 1298690395\n",
    "message = \"¡El codigo en VS Code ha terminado!\"\n",
    "\n",
    "# Envía la notificación\n",
    "response = send_telegram_message(telegram_token, chat_id, message)\n",
    "print(response.json())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
