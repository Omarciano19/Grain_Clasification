{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRAIN 2:\n",
    "Modelos de clasificación de trigo y maiz, se entrena un modelo para clasificar todo el grano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, Activation\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping\n",
    "\n",
    "import  imblearn\n",
    "from imblearn.over_sampling import  ADASYN\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "#from PIL import image\n",
    "#import tensorflow-gpu\n",
    "#from bayes_opt import BayesianOptimization\n",
    "\n",
    "\n",
    "print(tf.__version__)\n",
    "#tf.debugging.set_log_device_placement(True)\n",
    "#-------------------------------------------------------------------------------\n",
    "import time\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iniciamos configurando tensorflow para usar la GPU, al igual que tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"log_dir = \"logs/both/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "print(log_dir)\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "if len(tf.config.list_physical_devices('GPU'))>0:\n",
    "    physical_devices = tf.config.list_physical_devices('GPU')\n",
    "    print(physical_devices)\n",
    "    tf.config.experimental.set_virtual_device_configuration(physical_devices[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)])\n",
    "    print(\"Virtual GPU devices: \", tf.config.list_logical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.debugging.set_log_device_placement(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ambos granos: Trigo y Maiz\n",
    "Generamos dos iteradores de carpetas para los conjuntos de datos de validación y de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directorios de entrenamiento y validación\n",
    "train_dir = '../grainspace/pre/both/train'\n",
    "validation_dir = '../grainspace/pre/both/validation'\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,          # Normaliza los valores de los píxeles\n",
    "    shear_range=0.2,         # Aplica transformaciones de corte\n",
    "    zoom_range=0.2,          # Aplica zoom aleatorio\n",
    "    horizontal_flip=True     # Invierte las imágenes horizontalmente\n",
    ")\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    train_dir,  # Directorio con las imágenes de entrenamiento\n",
    "    target_size=(150, 150),     # Tamaño de las imágenes\n",
    "    batch_size=32,              # Tamaño del lote\n",
    "    class_mode='categorical'         # Tipo de clasificación (binary, categorical, etc.)\n",
    ")\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_images, batch_labels = next(train_generator)\n",
    "\n",
    "# Assuming the images are in the first channel of the batch\n",
    "sample_images = batch_images[:, :, :, 0]\n",
    "\n",
    "# Plot the first few images\n",
    "num_images_to_plot = 5\n",
    "fig, axes = plt.subplots(1, num_images_to_plot, figsize=(15, 5))\n",
    "for i in range(num_images_to_plot):\n",
    "    axes[i].imshow(sample_images[i])\n",
    "    axes[i].axis('on')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la arquitectura del modelo, una red neural convolucional de 4 capas convolucionales, y dos capas densas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_layers = [0, 1, 2]\n",
    "layer_sizes = [32, 64, 128]\n",
    "conv_layers = [1, 2, 3]\n",
    "\n",
    "for dense_layer in dense_layers:\n",
    "    for layer_size in layer_sizes:\n",
    "        for conv_layer in conv_layers:\n",
    "            NAME = \"{}-conv-{}-nodes-{}-dense-{}\".format(conv_layer, layer_size, dense_layer, int(time.time()))\n",
    "            print(NAME)\n",
    "\n",
    "            model = Sequential()\n",
    "\n",
    "            model.add(Conv2D(layer_size, (3, 3), input_shape=(150, 150, 3)))\n",
    "            model.add(Activation('relu'))\n",
    "            model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "            for l in range(conv_layer-1):\n",
    "                model.add(Conv2D(layer_size, (3, 3)))\n",
    "                model.add(Activation('relu'))\n",
    "                model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "            model.add(Flatten())\n",
    "            for _ in range(dense_layer):\n",
    "                model.add(Dense(layer_size))\n",
    "                model.add(Activation('relu'))\n",
    "            \n",
    "            model.add(Dropout(0.5))\n",
    "            model.add(Dense(len(train_generator.class_indices)))\n",
    "            model.add(Activation('softmax'))\n",
    "            \n",
    "            \n",
    "\n",
    "            tensorboard = TensorBoard(log_dir=\"logs/G600_both/{}\".format(NAME))\n",
    "            \n",
    "            model.summary()\n",
    "            model.compile(loss='binary_crossentropy',\n",
    "                          optimizer='adam',\n",
    "                          metrics=['accuracy'],\n",
    "                          )\n",
    "\n",
    "            early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "            history = model.fit(\n",
    "                train_generator,\n",
    "                steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "                validation_data=validation_generator,\n",
    "                validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
    "                epochs=30,\n",
    "                callbacks=[tensorboard, early_stopping],\n",
    "                batch_size=32\n",
    "                )\n",
    "            # Evaluación en conjunto de validación\n",
    "            loss, accuracy = model.evaluate(validation_generator)\n",
    "            print(f'Loss: {loss}')\n",
    "            print(f'Accuracy: {accuracy}')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"model = keras.Sequential([\n",
    "    keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(512, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(len(train_generator.class_indices), activation='softmax')\n",
    "\n",
    "])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"model = keras.Sequential([\n",
    "    keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Conv2D(128, (3, 3), activation='relu'),  # Capa de convolución adicional\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(512, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(256, activation='relu'),  # Capa densa adicional\n",
    "    keras.layers.Dense(len(train_generator.class_indices), activation='softmax')\n",
    "])\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
